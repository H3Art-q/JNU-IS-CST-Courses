# 数值计算基础（20级信科院）

*Sorted out by* $\text{H3Art}$

---

1. (10 Points) Apply classic Gram-Schimdt orthogonalization to find the full QR factorization of the matrix $\begin{bmatrix}
    2 & 3 \\
    -2 & -6 \\
    1 & 0
\end{bmatrix}$.

---

2. (10 Points) Given a square matrix $\mathbf{A} = \begin{bmatrix}
    1 & 2 \\
    4 & 3
\end{bmatrix}$, please answer the following questions:

(1) Find all eigenvalues and eigenvectors of $\mathbf{A}$;

(2) Apply three steps of Power Iteration with initial vector $\mathbf{x_0} = (1, 0)$.

---

3. **【果园这边没教】**(20 Points) Apply the Trapezoid Rule, Simpson's Rule and Mid-point Rule to approximate the integral $\displaystyle\int_0^1 x^2\mathrm{d}x$ . Compute the error by comparing with the exact value from calculus.

---

4. (15 Points) If the $n \times n$ matrix $\mathbf{A}$ is strictly diagonally dominant, then for every vector $\mathbf{b}$ and every starting guess, the Gauss-Seidel Method applied to $\mathbf{Ax}=\mathbf{b}$ converges to the unique solution.

---

5. (15 Points) Please prove the following: Let $\mathbf{A}$ be an $n\times n$ matrix with real eigenvalues $\lambda_1, \dots, \lambda_n$, satisfying $|\lambda_1|>|\lambda_2|\geq|\lambda_3|\geq\dots\geq|\lambda_n|$. Assume that the eigenvalues of $\mathbf{A}$ span $R^n$. For almost every initial vector, the Power Iteration method converges to an eigenvector associated to $\lambda_1$.

---

6. (15 Points) Given the following:

- $\mathbf{x}$ and $\mathbf{w}$: two vectors with $||\mathbf{x}||_2 = ||\mathbf{w}||_2$;
- $\mathbf{u = w - x}$ and $\displaystyle\mathbf{v} = \frac{\mathbf{u}}{||\mathbf{u}||_2}$
- $\mathbf{H = I - 2vv^\top}$

Please prove that $\mathbf{Hx=w}$ and $\mathbf{Hw=x}$.

---

7. (15 Points) Please compare the following methods: Jacobi Method, Gauss-Seidel Method, SOR, Conjugate Gradient Method and Preconditioned Conjugate Gradient Method.